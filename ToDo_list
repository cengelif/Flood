"""
Decisions:
- Should we eliminate RTs: The default should be YES.
- Numbers are used as features
- if a clustering does not provide any candidate, change the thresholds in the next iteration!
- change token pattern of TfidfVectorizer! take one character features into account: I, a, ... : Elif did it.
- Should we eliminate tweets that contain only one normal word (.alpha())? It can be an option.: No, use other clues!

ToDo:
- n_clusters, for k should be assigned automatically at the beginning.
- silhouette score can be provided with an explanation.
- Write each group to files.
- while writing to the file: write remaining tweets as "rest".
- based on the identified/labeled tweets, a classifier may be able to predict label of a new cluster.
- support configuration files
- add create a classifier, test a classifier by classifying 10 docs and asking if they are good! option based on annotation after a while!
- tokenizer should process:  â€˜
- put an option to go out of the complete iteration. Currently q quits only from the current iteration.
- What should we do with the last batch of the clusters after we group majority of the tweets?
- Parallel processing for datasets taht are bigger than n a certain number.
"""
